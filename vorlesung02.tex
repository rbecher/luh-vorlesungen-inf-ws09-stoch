\par\noindent Aus der Menge der Permutationen betrachten wir eine spezifische Teilmenge.\\
Sei $k_1,\ldots,k_n \in \mathbb{N}_0$ mit $k_1+\ldots+k_n=r$. Einen so genannter ``Besetzungszahlvektor'' drückt man beispielsweise so aus:
\begin{equation}
	\begin{split}
	& \{(x_1,\ldots,x_n)\in\mathbb{P}_n^r;\ |\{j; j\in\{1,\ldots,r\}, x_j=i\}|=k_i, 1\leq i\leq n\}|\\
	=	& \{(x_1,\ldots,x_n)\in\mathbb{P}_n^r;\ \text{Genau $k_i$ der $r$ Komponenten $(x_1,\ldots,x_r)$ sind gleich $i$}, 1\leq i \leq n\}
	\end{split}
	\label{def:besetzungszahlvektor}
\end{equation}

Die Länge oder Mächtigkeit dieser Menge ist wie folgt:
\begin{equation*}
	\begin{split}
	 |\ref{def:besetzungszahlvektor}| & = \binom{r}{k_1}\binom{r-k_1}{k_2}\binom{r-k_1-k_2}{k_3}\cdots\binom{r-k1-\ldots-k_{n-1}}{k_n}\\
	 & =	\frac{r!}{k_1!\cancel{(r-k_1)!}}\cdot \frac{\cancel{(r-k_1)!}}{k_2!\cancel{(r-k_1-k_2)!}}\cdots \frac{\cancel{(r-k_1-\ldots-k_n)!}}{k_n!}\\
	 & = \frac{r!}{k_1!\cdots k_n!} % (r-k_1)! durchstreichen ... strike?
	\end{split}
\end{equation*}

% Binomischer Lehrsatz
% => Multinomialer Lehrsatz durch Verallgemeinerung

\subsection{Binomischer Lehrsatz}

Es folgt aus dem (bekannten) binomischen Lersatz durch Verallgemeinerung der multinomiale Lehrsatz.

\begin{equation}
n^r = \sum_{\substack{(k_1,\ldots,k_n)\in\mathbb{N}_0^n\\k_1+\ldots+k_n=r}}{\frac{r!}{k_1!\cdots k_n!}} % Anzahl der Summanden = n+r-1 über r
\label{def:nhochr}
\end{equation}

\begin{equation}
	\begin{split}
	|\ref{def:nhochr}| &= \binom{n+r-1}{r}
	\end{split}
\end{equation}

\subsection{Beispiel}
O.B.d.A. sind $r$ Personen im Raum, $n=365$ seien die Anzahle der Tage im Jahr und $r\leq n$.\\
Gesucht: Wahrscheinlickeit, dass mindestens $2$ der $r$ Personen am gleichen Tag Geburtstag haben.
\begin{itemize}
	\item $ \Omega = \{ (x_1,\ldots,x_r); x_i \  \} $
	\item $ \mathfrak{A}=\mathfrak{P}(\Omega) $
	\item $ P(A)=\frac{|A|}{|\Omega|}, A\subseteq\Omega $
	\item Alle möglichen r-Tupel von Geburtstagen sind gleich wahrscheinlich, also
	\item $A= \{ (x_1,\ldots,x_r)\in\Omega; i,j \in \{1,\ldots,r\}, i\neq j, x_i=x_j \}$
	\item $P(A) = 1-P(A^c)$\\
				In vielen Fällen ist es ein valider ``Trick'', statt der Ergebnismenge das Gegenergebnis zu berechnen
	\item $A^c = \{ (x_1,\ldots,x_r)\in\Omega; x_1,\ldots,x_r \text{ paarweise verschieden} \}$
	\item $|A^c|=n(n-1)\cdots(n-r+1)$
	\item $P(A)=1- \frac{n(n-1)\cdots(n-r+1)}{n^r}$
\end{itemize}

\begin{equation*}
P(A)=\begin{cases}
> 1/2& \text{wenn $r>23$},\\
0,706& \text{wenn $r=30$},\\
0,994& \text{wenn $r=60$}.
\end{cases}
\end{equation*}

\subsection{Die Siebformel}
	 
Seien $A_1,A_n$ Ereignisse in W-Raum $(\Omega,\mathfrak{A},P)$
\begin{equation}
\begin{split}
P(A_1\cup A_2) 	&= P(A_1 \cup (A_2 \cap (A_1 \cap A_2)^c))\\
								&= P(A_1) + P(A_2 \cap (A_1 \cap A_2)^c)\\
								&= P(A_1) + P(A_2) - P(A_1 \cap A_2)
\end{split}
\label{example:siebformel}
\end{equation}

\par\noindent Dies führt uns zu folgendem:
Seien $A_1,\ldots,A_n$ Ereignisse. Dann
\begin{equation}
	P(\bigcup_{k=1}^n{A_k}) = \sum_{k-1}^n{(-1)^{k-1}\sum_{1\leq j_1<\ldots<j_k\leq n}{P(A_{j_1}\cap \ldots \cap A_{j_k})}}
	\label{def:siebformel}
\end{equation}

\par\noindent Wie leicht überprüfbar ist, ist \eqref{example:siebformel} eine Anwendung von \eqref{def:siebformel}.

\subsection{Beispiel}
Sei
\begin{itemize}
	\item $\Omega = \{ \pi; \pi:\{1,\ldots,n\} \rightarrow \{1,\ldots,n\}$ bijektiv
	\item $|\Omega|=n!$
	\item $\mathfrak{A}=\mathfrak{P}(\Omega)$
	\item $P$ das diskrete Laplace'sche W-Ma\ss\ auf $\Omega$
	\item $A_i= \{ \pi \in \Omega; \pi(i)=i\},\ 1\leq i \leq n$
	\item $\bigcup_{i=1}^n{A_i} = \{ \pi\in\Omega; \text{Es gibt ein $i\in\{1,\ldots,n\}$ mit $\pi(i)=i$}\}$
\end{itemize}
\par\noindent Dann
\begin{equation}
	\begin{split}
		P(\bigcup_{i=1}^n{A_i}) &=\sum_{k-1}^n{(-1)^{k-1}\sum_{1\leq j_1<\ldots<j_k\leq n}{\frac{|A_{j_1}\cap\ldots\cap A_{j_k}|}{|\Omega|}}}\\
														&=\sum_{k=1}^n{(-1)^{k-1}\sum_{...}{\frac{(n-k)!}{n!}}}\\
														&=\sum_{k=1}^n{(-1)^{k-1}\binom{n}{k}\cdot \frac{(n-k)!}{n!}}\\
														&=\sum_{k=1}^n{(-1)^{k-1}\frac{1}{k!}}
	\end{split}
\end{equation}

\par\noindent und wegen
\begin{equation}
	\begin{split}
		\bigcap_{i=1}^n{A_i^c}	&= \left(\bigcup_{i=1}^nA_i\right)^c\\
														&=\{\pi \in \Omega; \forall i \in \{1,\ldots,n\}\text{ ist } \pi(i)\neq i\}
	\end{split}
\end{equation}

\par\noindent ist

\begin{equation}
	\begin{split}
		P\left(\bigcap_{i=1}^n{A_i^c}\right)	&=1-\sum_{k=1}^n{(-1)^{k-1} \frac{1}{k!}}\\
															&=\sum_{k=0}^n{(-1)^{k} \frac{1}{k!}}\\
															&\xrightarrow[n\rightarrow\infty]{}\sum_{k=0}^{\infty}{(-1)^k \frac{1}{k!}}\\
															&=e^{-1}\\
															&\approx 0.37
	\end{split}
\end{equation}

\subsection{Weitere Beispiele für W-Maße}

Sei $\emptyset\neq\Omega$, $\mathfrak{A}$ $\sigma$-Algebra mit $\{\omega\}\in \mathfrak{A}$ für jedes $\omega\in\Omega$.\\
Sei $P$ W-Maß auf $\Omega$ mit der Eigenschaft, dass eine abzählbare Menge $\Omega_o\subseteq\Omega$ existiert mit $P(\Omega_0)=1$\\
Dann \[P\left(\Omega_0^c\right) = 1-P\left(\Omega_0^c\right)=0\]
Für $A\in \mathfrak{A}$ gilt
\begin{equation}
	\begin{split}
		P(A)	&=P\left((A\cap\Omega_0)+(A\cap\Omega_0^c)\right) \\
					&= P(A\cap\Omega_0) + P(A\cap\Omega_0^c)\\ % last is disjunkt
					&= P\left(\sum_{\omega \in A\,\cap\,\Omega_0}{\{\omega\}}\right)\\
					&=\sum_{\omega \in A\,\cap\,\Omega_o}{P\left(\{\omega\}\right)}\\
					&=\sum_{\omega \in \Omega}{P\left(\{\omega\}\right)\delta_\omega(A)}
	\end{split}
\end{equation}

\par\noindent Für $\omega\in\Omega$ heißt $\delta_\omega:\mathfrak{A} \rightarrow [0,1]$, definiert durch
\begin{equation*}
%		0 & \omega\not\in A.
	\delta_\omega(A)=\begin{cases}
		1	&	\omega\in A,\\
		0 & \omega\not\in A.
	\end{cases}
\end{equation*}
das Einpunktmaß oder \textbf{\href{http://de.wikipedia.org/wiki/Diracmass}{Dirac-Maß} in $\omega$}.\\

\par\noindent Es gilt also \[P=\sum_{\omega\in\Omega_0}{P(\{\omega\})}\cdot\delta_\omega.\]
\par\noindent Solche W-Maße heißen \textbf{diskrete W-Maße}.

\subsection{Die Borelsche $\sigma$-Algebra}

\par\noindent Betrachte den Fall $\Omega=\mathbb{R}$\\
\[
	\mathfrak{B}=\mathfrak{A}=\bigcap_{\substack{\mathfrak{A}^*\text{ $\sigma$-Algebra auf }\mathbb{R}\\\mathfrak{A}^*\supseteq\{(-\infty,x]; x\in\mathbb{R}\}}}\mathfrak{A}^*
\]
ist die Borelsche $\sigma$-Algebra auf $\mathbb{R}$.

\par\noindent Beachte
\[\mathfrak{B}\neq \mathfrak{P}(\mathbb{R})\]

\par\noindent $\mathfrak{B}$ enthält alle offenen, abgeschlossenen und ohne Intervalle Teilmengen von R.\\ % meh, besser formulieren

\subsection{Verteilungsfunktionen}

\par\noindent Sei $F:\mathbb{R}\rightarrow \mathbb{R}$ Funktion mit folgenden Eigenschaften:
\begin{enumerate}
	\item $F$ ist monoton wachsend
	\item $F$ ist rechtsseitig stetig
	\item \[\lim_{x\rightarrow-\infty}F(x)=0\]
	\item \[\lim_{x\rightarrow+\infty}F(x)=1\]
\end{enumerate}

\par\noindent Es existiert genau ein W-Maß $P$ auf $\mathfrak{B}$ (auf $\mathbb{R}$) mit der Eigenschaft, dass
\begin{equation}
	P\left((-\infty,x])\right)=F(x),\ \forall x\in\mathbb{R}
\end{equation}

\par\noindent $F$ heißt die zu $P$ gehörige \href{http://de.wikipedia.org/wiki/Verteilungsfunktion}{\textbf{Verteilungsfunktion}}.

\par\noindent Für $(a,b]$ mit $-\infty<a<b<+\infty$ ist
\begin{equation}
	P((a,b]) = P((-\infty,b]) - P(-\infty,a]) = F(b)-F(a)
\end{equation}

\subsection{Verteilungsdichten}

Sei $f:\mathbb{R} \rightarrow \mathbb{R}_+$ (uneigentlich) \href{http://de.wikipedia.org/wiki/Riemann-Integral#Uneigentliche_Integrale}{Riemann-integrierbar} mit  % Bildmenge ist genau [0,\infty)
\begin{equation}
	\int_{- \infty }^{+\infty}{f(t)dt}=1
\end{equation}

\par\noindent Setze 
\begin{equation}
	F(x)=\int_{- \infty}^{+ \infty}{f(t)dt},\ -\infty <x<+\infty 
\end{equation}

\par\noindent $F$ ist Verteilungsfunktion eines W-Maßes $P$ auf $\mathbb{R}$.

\par\noindent $f$ heißt \href{http://de.wikipedia.org/wiki/Verteilungsdichte}{\textbf{Wahrscheinlichkeitsdichte}} (oder einfach "`Dichte"') von $P$.

\subsubsection{Spezialfälle}

\begin{itemize}
	% a
	\item 
	\begin{equation*}
		f(t)=\begin{cases}
		0	&	,\ x<a,\\
		\frac{1}{b-a} & ,\ a\leq x\leq b,\\
		0 & ,\ x>b.
	\end{cases}
	\end{equation*}
	\begin{equation*}
		F(x)=\begin{cases}
		0	&	,\ x<a,\\
		\frac{x-a}{b-a} & ,\ a\leq x\leq b,\\
		1 & ,\ x>b.
	\end{cases}
	\end{equation*}
	%f(t)= 0 \forall x<a,\ and\ \frac{1}{b-a} \forall a\leq x\leq b\ oder\ 0 \forall x>b$\\ % cases
	%			$F(x) = 0 \forall x<a,\ and\ \frac{x-a}{b-a} \forall a\leq x\leq b\ oder\ 1 \forall x>b$ % cases
	% b
	\item \[
		f(t) = \frac{1}{\sqrt{2\pi\sigma^2}} exp(-\frac{1}{2}\frac{(t-a)^2}{\sigma^2}), -\infty<t<+\infty, (a\in R, \sigma^2>0) % das ist die glockenkurve
	\]
	\textit{(Anmerkung: Diese Verteilungsdichte wird auch Standardnormalverteilung genannt. Die Verteilungsfunktion dafür produziert die so genannte Gauß'sche Glockenkurve)}
Dann ist \[\int_{-\infty}^{+\infty}{f(t)dt=1}\] und somit
\begin{equation*}
	\begin{split}
		F(x) 		& = \int_{-\infty}^{+\infty}{\frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{1}{2}\frac{(t-a)^2}{\sigma^2})dt}\\
				 		& = \phi(\frac{x-a}{\sigma})\\
		\phi(x)	& = \int_{-\infty}^{+\infty}{\frac{1}{\sqrt{2\pi\sigma^2}}exp(-\frac{t^2}{2})}dt, x\in \mathbb{R}
	\end{split}
\end{equation*}
\end{itemize}

